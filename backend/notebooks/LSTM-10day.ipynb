{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fa37aca8",
      "metadata": {},
      "source": [
        "## Setup & imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4147c357",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: make \"backend/\" importable as a package root\n",
        "import sys, pathlib\n",
        "ROOT = pathlib.Path(__file__).resolve().parents[1]  # backend/\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "\n",
        "# Core imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from app.services.backtest import (\n",
        "    fetch_prices, add_features, make_windows, build_model\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b580abfe",
      "metadata": {},
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f1d6df1",
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "TICKER   = \"AAPL\"     # any equity/ETF/crypto (crypto often like \"BTC-USD\")\n",
        "CONTEXT  = 100        # last N sessions used as the context window\n",
        "LOOKBACK = 60         # <= 80 so we can train with 80 sessions for backtest\n",
        "H_BACK   = 20         # backtest horizon (predict last 20 sessions)\n",
        "H_FORE   = 10         # forecast horizon (predict next 10 sessions)\n",
        "\n",
        "# (Optional) output\n",
        "SAVE_JSON = True\n",
        "OUT_JSON  = \"unified_backtest_forecast.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "508699f7",
      "metadata": {},
      "source": [
        "## Fetch data & build features (reusing service helpers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b053a40",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Overfetch calendar days so we reliably get >= CONTEXT + LOOKBACK + 40 sessions after dropna\n",
        "overfetch_days = CONTEXT + LOOKBACK + 200\n",
        "start_date = (datetime.utcnow() - timedelta(days=overfetch_days)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "raw = fetch_prices(TICKER, start=start_date, end=None, interval=\"1d\")\n",
        "feat = add_features(raw)\n",
        "\n",
        "# Keep only the last CONTEXT sessions for the combined view\n",
        "if len(feat) < CONTEXT + 5:\n",
        "    raise ValueError(f\"Not enough data. Need at least ~{CONTEXT+5} feature rows, got {len(feat)}\")\n",
        "\n",
        "ctx = feat.iloc[-CONTEXT:].copy()\n",
        "ctx.index = pd.to_datetime(ctx.index)\n",
        "\n",
        "# Targets = next-session log-return\n",
        "ctx[\"target_ret\"] = ctx[\"log_ret\"].shift(-1)\n",
        "ctx = ctx.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06acca35",
      "metadata": {},
      "source": [
        "## One-shot backtest on the last 20 sessions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61868545",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training slice for backtest = everything up to the last H_BACK rows\n",
        "start_idx = len(ctx) - H_BACK\n",
        "if start_idx <= LOOKBACK:\n",
        "    raise ValueError(f\"Training slice too short for LOOKBACK={LOOKBACK}. \"\n",
        "                     f\"Have {start_idx} training rows. Lower LOOKBACK or increase CONTEXT.\")\n",
        "\n",
        "X_df = ctx[[\n",
        "    \"Close\",\"Volume\",\"log_ret\",\"ret\",\n",
        "    \"roll_mean_7\",\"roll_std_7\",\"roll_mean_21\",\"roll_std_21\",\n",
        "    \"rsi_14\",\"macd\",\"macd_signal\",\"macd_diff\",\n",
        "    \"bb_width\",\"ret_lag1\",\"ret_lag3\",\"ret_lag5\",\n",
        "    \"vol_7\",\"vol_21\",\"z_close_21\",\n",
        "]].astype(\"float32\")\n",
        "y = ctx[\"target_ret\"].astype(\"float32\").values\n",
        "dates = ctx.index\n",
        "\n",
        "# Fit scalers on train slice only\n",
        "train_X_df = X_df.iloc[:start_idx]\n",
        "train_y    = y[:start_idx]\n",
        "\n",
        "scaler_X = StandardScaler().fit(train_X_df.values)\n",
        "scaler_y = StandardScaler().fit(train_y.reshape(-1,1))\n",
        "X_train  = scaler_X.transform(train_X_df.values)\n",
        "y_train_s = scaler_y.transform(train_y.reshape(-1,1)).ravel()\n",
        "\n",
        "# Build windows and train\n",
        "Xw, yw = make_windows(X_train, y_train_s, LOOKBACK, H_BACK)\n",
        "if len(Xw) == 0:\n",
        "    raise ValueError(\"No training windows for backtest. Adjust LOOKBACK/H_BACK.\")\n",
        "\n",
        "model_back = build_model(LOOKBACK, Xw.shape[2], H_BACK)\n",
        "model_back.fit(Xw, yw, epochs=24, batch_size=32, verbose=0)\n",
        "\n",
        "# Predict last H_BACK from final LOOKBACK training rows\n",
        "last_block_raw = train_X_df.values[-LOOKBACK:]\n",
        "last_block = scaler_X.transform(last_block_raw).reshape(1, LOOKBACK, Xw.shape[2])\n",
        "next_ret_s = model_back.predict(last_block, verbose=0)[0]\n",
        "next_ret   = scaler_y.inverse_transform(next_ret_s.reshape(-1,1)).ravel()\n",
        "\n",
        "# Convert returns to prices\n",
        "last_price_bt = float(ctx[\"Close\"].iloc[start_idx-1])\n",
        "pred_back_prices = last_price_bt * np.exp(np.cumsum(next_ret))\n",
        "actual_back = ctx[\"Close\"].iloc[start_idx : start_idx + H_BACK].values.astype(\"float64\")\n",
        "\n",
        "back_dates = dates[start_idx : start_idx + H_BACK]\n",
        "back_df = pd.DataFrame({\n",
        "    \"date\": back_dates,\n",
        "    \"actual\": actual_back,\n",
        "    \"pred_back\": pred_back_prices[:len(actual_back)]\n",
        "}).set_index(\"date\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfe87571",
      "metadata": {},
      "source": [
        "## One-shot forecast next 10 sessions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac499965",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrain on full CONTEXT slice and predict H_FORE forward\n",
        "scaler_X2 = StandardScaler().fit(X_df.values)\n",
        "scaler_y2 = StandardScaler().fit(y.reshape(-1,1))\n",
        "X_all  = scaler_X2.transform(X_df.values)\n",
        "y_all_s = scaler_y2.transform(y.reshape(-1,1)).ravel()\n",
        "\n",
        "Xw2, yw2 = make_windows(X_all, y_all_s, LOOKBACK, H_FORE)\n",
        "if len(Xw2) == 0:\n",
        "    raise ValueError(\"No training windows for forecast. Adjust LOOKBACK/H_FORE/CONTEXT.\")\n",
        "\n",
        "model_fore = build_model(LOOKBACK, Xw2.shape[2], H_FORE)\n",
        "model_fore.fit(Xw2, yw2, epochs=24, batch_size=32, verbose=0)\n",
        "\n",
        "last_block_raw2 = X_df.values[-LOOKBACK:]\n",
        "last_block2 = scaler_X2.transform(last_block_raw2).reshape(1, LOOKBACK, Xw2.shape[2])\n",
        "next_ret_s2 = model_fore.predict(last_block2, verbose=0)[0]\n",
        "next_ret2   = scaler_y2.inverse_transform(next_ret_s2.reshape(-1,1)).ravel()\n",
        "\n",
        "last_price = float(ctx[\"Close\"].iloc[-1])\n",
        "pred_fore_prices = last_price * np.exp(np.cumsum(next_ret2))\n",
        "\n",
        "# Build future dates: business days for equities, daily for crypto-like tickers\n",
        "last_dt = ctx.index[-1]\n",
        "is_crypto = TICKER.upper().endswith(\"-USD\")\n",
        "freq = \"D\" if is_crypto else \"B\"\n",
        "future_idx = pd.date_range(last_dt + pd.tseries.frequencies.to_offset(\"D\"), periods=H_FORE, freq=freq)\n",
        "\n",
        "fore_df = pd.DataFrame({\n",
        "    \"date\": future_idx,\n",
        "    \"pred_fore\": pred_fore_prices\n",
        "}).set_index(\"date\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e82f78",
      "metadata": {},
      "source": [
        "## Merge + metrics + plot (single chart)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71d9ab17",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge actuals (last CONTEXT) with predicted segments\n",
        "actual_df = ctx[[\"Close\"]].rename(columns={\"Close\":\"actual\"}).iloc[-CONTEXT:]\n",
        "combined = actual_df.join(back_df[[\"pred_back\"]], how=\"left\")\n",
        "\n",
        "# Append forecast rows (no actuals there)\n",
        "combined = pd.concat([combined, fore_df], axis=0)\n",
        "\n",
        "# Simple friendly metrics on backtest window\n",
        "# Accuracy = directional hit-rate comparing day-to-day changes\n",
        "if len(back_df) > 1:\n",
        "    da = back_df[\"actual\"].diff().to_numpy()\n",
        "    dp = back_df[\"pred_back\"].diff().to_numpy()\n",
        "    valid = np.isfinite(da) & np.isfinite(dp)\n",
        "    hits = (np.sign(da[valid]) == np.sign(dp[valid])).sum()\n",
        "    denom = valid.sum()\n",
        "    accuracy_pct = (hits / denom * 100) if denom else 0.0\n",
        "else:\n",
        "    accuracy_pct = 0.0\n",
        "\n",
        "mae_dollar = float(mean_absolute_error(back_df[\"actual\"], back_df[\"pred_back\"])) if len(back_df) else 0.0\n",
        "mape_pct   = float(mean_absolute_percentage_error(back_df[\"actual\"], back_df[\"pred_back\"]) * 100) if len(back_df) else 0.0\n",
        "rmse       = float(np.sqrt(mean_squared_error(back_df[\"actual\"], back_df[\"pred_back\"])) ) if len(back_df) else 0.0\n",
        "\n",
        "metrics = {\n",
        "    \"ticker\": TICKER,\n",
        "    \"context_sessions\": CONTEXT,\n",
        "    \"lookback\": LOOKBACK,\n",
        "    \"backtest_horizon\": H_BACK,\n",
        "    \"forecast_horizon\": H_FORE,\n",
        "    \"accuracy_pct\": accuracy_pct,\n",
        "    \"avg_abs_error\": mae_dollar,\n",
        "    \"mape_pct\": mape_pct,\n",
        "    \"rmse\": rmse,\n",
        "}\n",
        "\n",
        "metrics\n",
        "\n",
        "if SAVE_JSON:\n",
        "    import json\n",
        "    payload = {\n",
        "        \"metrics\": metrics,\n",
        "        \"series\": combined.reset_index().assign(date=combined.index.strftime(\"%Y-%m-%d\")).to_dict(orient=\"records\"),\n",
        "    }\n",
        "    with open(OUT_JSON, \"w\") as f:\n",
        "        json.dump(payload, f, indent=2)\n",
        "\n",
        "# Plot: one chart with (1) actuals (last 100), (2) backtest preds (last 20), (3) forecast preds (next 10)\n",
        "plt.figure(figsize=(11,5))\n",
        "combined[\"actual\"].plot(label=\"Actual (last 100)\", lw=2, color=\"black\")\n",
        "\n",
        "# Backtest predicted segment (overlapping last 20)\n",
        "combined[\"pred_back\"].plot(label=\"Predicted (backtest last 20)\", lw=2, color=\"tab:orange\")\n",
        "\n",
        "# Forecast segment (future 10)\n",
        "combined[\"pred_fore\"].plot(label=\"Predicted (forecast next 10)\", lw=2, linestyle=\"--\", color=\"tab:blue\")\n",
        "\n",
        "plt.title(f\"{TICKER} â€” Unified Backtest (20) + Forecast (10) using last {CONTEXT} sessions, lookback={LOOKBACK}\")\n",
        "plt.xlabel(\"Date\"); plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
